{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GAN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNx25u+Ue+9JXJApARJhLd4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tristanoprofetto/neural-networks/blob/main/GAN/DCGAN/GAN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xv4HMGpXQo7t"
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import keras\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Reshape, Dense, Conv2D, Conv2DTranspose, UpSampling2D, Lambda, Dropout, Activation, BatchNormalization, Flatten, Layer\n",
        "from keras import backend as K"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ltfq2uYRjgg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "5656bbaa-f73d-45d5-f5ad-540d75067d2f"
      },
      "source": [
        "images = np.load(\"gs://quickdraw_data/apple.npy\")\n",
        "\n",
        "images = images / 255\n",
        "images = np.reshape(images, (images.shape[0], 28, 28, 1))\n",
        "\n",
        "width, height = images.shape[1:3]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-30d06874dde1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gs://quickdraw_data/apple.npy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gs://quickdraw_data/apple.npy'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3bv036WRm_4"
      },
      "source": [
        "def Discriminator(depth=64, dropout=0.4):\n",
        "\n",
        "  image = Input((width, height, 1))\n",
        "\n",
        "  # Convolutional Layers\n",
        "  l1 = Conv2D(depth, kernel_size=5, strides=2, padding='same', activation='relu')(image)\n",
        "  l1 = Dropout(dropout)(l1)\n",
        "\n",
        "  l2 = Conv2D(depth * 2, kernel_size=5, strides=2, activation='relu')(l1)\n",
        "  l2 = Dropout(dropout)(l2)\n",
        "\n",
        "  l3 = Conv2D(depth * 4, kernel_size=5, strides=2, padding='same', activation='relu')(l2)\n",
        "  l3 = Dropout(dropout)(l3)\n",
        "\n",
        "  l4 = Conv2D(depth * 8, kernel_size=5, strides=2, padding='same', activation='relu')(l3)\n",
        "  l4 = Flatten()(Dropout(dropout)(l4))\n",
        "\n",
        "  output = Dense(1, activation='sigmoid', name=\"prediction\")(l4)\n",
        "\n",
        "  model = Model(inputs=image, outputs=output)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npGgR3XETzgz"
      },
      "source": [
        "def Generator(noise_dim=32, depth=64, dropout=0.4):\n",
        "\n",
        "  noise = Input((noise_dim,))\n",
        "\n",
        "  # Input Layer\n",
        "  l1 = Dense(7*7*depth)(noise)\n",
        "  l1 = BatchNormalization(momentum=0.9)(l1)\n",
        "  l1 = Activation(activation='relu')(l1)\n",
        "  l1 = Reshape((7, 7, depth))(l1)\n",
        "  l1 = Dropout(dropout)(l1)\n",
        "\n",
        "  \n",
        "  # De-Convolutional Layers\n",
        "  d1= UpSampling2D()(l1)\n",
        "  d1 = Conv2DTranspose(int(depth / 2), kernel_size=5, padding='same', activation=None)(d1)\n",
        "  d1 = BatchNormalization(momentum=0.9)(d1)\n",
        "  d1 = Activation(activation='relu')(d1)\n",
        "\n",
        "  d2= UpSampling2D()(d1)\n",
        "  d2 = Conv2DTranspose(int(depth / 4), kernel_size=5, padding='same', activation=None)(d2)\n",
        "  d2 = BatchNormalization(momentum=0.9)(d2)\n",
        "  d2 = Activation(activation='relu')(d2)\n",
        "\n",
        "  d3= UpSampling2D()(d2)\n",
        "  d3 = Conv2DTranspose(int(depth / 8), kernel_size=5, padding='same', activation=None)(d3)\n",
        "  d3 = BatchNormalization(momentum=0.9)(d3)\n",
        "  d3 = Activation(activation='relu')(d3)\n",
        "\n",
        "  output = Conv2D(1, kernel_size=5, padding='same', activation='sigmoid')(d3)\n",
        "\n",
        "  model = Model(inputs=noise, outputs=output)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJlQ5vKNWw-R"
      },
      "source": [
        "disc = Discriminator()\n",
        "disc.compile(loss='binary_crossentropy', optimizer=keras.optimizers.rmsprop_v2, metrics=['binary_accuracy'])\n",
        "\n",
        "gen = Generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gA128T7bxSv"
      },
      "source": [
        "# Copying the weights from the dicriminator to the 'stopped discriminator' during training\n",
        "def copyWeights(source, target):\n",
        "  for i, layer in enumerate(source.layers):\n",
        "    target.layers[i].set_weights(source.layers[i].get_weights())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_7l_XOeV5dZ"
      },
      "source": [
        "def GAN():\n",
        "\n",
        "  Z = Input(shape=(32,))\n",
        "\n",
        "  image = gen(Z)\n",
        "\n",
        "  pred = disc(image)\n",
        "\n",
        "  model = Model(inputs=Z, outputs=pred)\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_avUlxJXcx5"
      },
      "source": [
        "model = GAN()\n",
        "model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.rmsprop_v2, metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUIafpQngJty"
      },
      "source": [
        "disc_ = Discriminator()\n",
        "disc_.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn3pLfeIXp73"
      },
      "source": [
        "def trainModel(epochs=2000, batch_size=128, noise_dim=32):\n",
        "\n",
        "  # Training metrics for discriminator and GAN\n",
        "  disc_metrics = []\n",
        "  disc_loss = 0\n",
        "  disc_accuracy =0\n",
        "\n",
        "  gan_metrics = []\n",
        "  gan_loss = 0\n",
        "  gan_accuracy =0\n",
        "\n",
        "\n",
        "  for i in range(epochs):\n",
        "\n",
        "    # Discriminator Training\n",
        "    real = np.reshape(data[np.random.choice(data.shape[0], batch_size, replace=False)], (batch_size, 28, 28, 1)]) \n",
        "    fake = generator.predict(np.random.uniform(-1, 1, size=[batch_size, noise_dim]))\n",
        "\n",
        "    X = np.concatenate((real, fake))\n",
        "\n",
        "    y = np.ones([2 * batch_size, 1]) - np.random.uniform(0, 0.1, [2 * batch_size, 1])\n",
        "    y[batch_size:,:] = 0\n",
        "    y[batch_size:,:] += np.random.uniform(0,0.1,[batch_size,1])\n",
        "    \n",
        "    disc_metrics.append(discriminator.train_on_batch(X,y))\n",
        "\n",
        "    disc_loss +=  disc_metrics[-1][0]\n",
        "    disc_accuracy += disc+metrics[-1][1]\n",
        "\n",
        "\n",
        "    # GAN Training\n",
        "    noise = np.random.uniform(-1, 1, size=[batch_size, noise_dim])\n",
        "    y = np.ones([batch_size, 1])\n",
        "\n",
        "    copy_weights(discriminator, discriminator)\n",
        "\n",
        "    gan_metrics.append(model.train_on_batch(noise, y))\n",
        "\n",
        "    gan_loss += gan_metrics[-1][0]\n",
        "    gan_accuracy += gan_metrics[-1][1]\n",
        "\n",
        "\n",
        "    # Visualizing Training History\n",
        "    if (i+1) % 20 == 0:\n",
        "      print('Epoch {}'.format(i))\n",
        "\n",
        "\n",
        "      noise = np.random.uniform(-1, 1, size=[16, noise_dim])\n",
        "\n",
        "      gen_images = generator.predict(noise)\n",
        "\n",
        "      plt.figure(figsize=(5,5))\n",
        "      for k in range(gen_images.shape[0]):\n",
        "        plt.subplot(4, 4, k+1)\n",
        "        plt.imshow(gen_images[k, :, :, 0], cmap='gray')\n",
        "\n",
        "      plt.tight_layout()\n",
        "      plt.show()\n",
        "\n",
        "  return disc_metrics, gan_metrics\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}